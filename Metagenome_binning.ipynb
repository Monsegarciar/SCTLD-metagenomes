{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b24a3a",
   "metadata": {},
   "source": [
    "### Preparing assembly files for binning\n",
    "To create a depth processing file, reads must be re-aligned to the contigs. This has been done using bowtie2 (can also be done using BWA). The next step would be to create a depth file with MetaBat2, convert that to be suitable for CONCOCT and MaxBin2, and then process these into bins. \n",
    "\n",
    "This is all assuming you have installed all of the softwares mentioned here. Use conda for quick install. If needed, the documentation for everything can be found here:\n",
    "\n",
    "MetaBat2: \n",
    "\n",
    "MaxBin2:\n",
    "\n",
    "CONCOCT: https://github.com/BinPro/CONCOCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da1fd1",
   "metadata": {},
   "source": [
    "#### MetaBat2\n",
    "The first piece of code here generates a fairly simple text file for the coverage of these files. Still looking into whether the same file cannot be used for all binners. So far no luck. The next set of code runs MetaBat2 itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a03a1a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-22de35fddd80>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#this creates a depth file for MetaBat\n",
    "#check names of the mapping files\n",
    "for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past\n",
    "do\n",
    "jgi_summarize_bam_contig_depths --outputDepth ../data/working/metabat_depth_\"$f\".txt ../../03_mapping/data/results/\"$f\".bam\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the actual MetaBat2 script\n",
    "metabat2 -i assembly.fa.gz -a depth.txt -o resA1/bin -v\n",
    "metabat2 -i ${out}/work_files/assembly.fa -a ${out}/work_files/metabat_depth.txt\\\n",
    "\t -o ${out}/metabat2_bins/bin -m $metabat_len -t $threads --unbinned\n",
    "\tif [[ $? -ne 0 ]]; then error \"Something went wrong with running MetaBAT2. Exiting\"; fi\n",
    "\tcomm \"metaBAT2 finished successfully, and found $(ls -l ${out}/metabat2_bins | grep .fa | wc -l) bins!\"\n",
    "\n",
    "\tif [ $checkm = true ]; then\n",
    "\t\trun_checkm ${out}/metabat2_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bc904",
   "metadata": {},
   "source": [
    "#### MaxBin2\n",
    "This creates the depth file for MaxBin2. This has been directly copied from the MetaWrap pipeline, because MaxBin2's own documentation is weirdly absent from the world. The program itself is also not very helpful, as it has no help message. Considering not running this module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2294f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-70357cb867cc>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past; do\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#this creates the MaxBin depth file SEE IF THERE IS AN ALTERNATIVE\n",
    "for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past; do\n",
    "    jgi_summarize_bam_contig_depths --outputDepth ../data/working/mb2_master_depth_\"$f\".txt --noIntraDepthVariance ../../03_mapping/data/results/\"$f\".bam\n",
    "    A=($(head -n 1 ../data/working/mb2_master_depth_\"$f\".txt)) \n",
    "    N=${#A[*]}\n",
    "done\n",
    "#the next bit breaks the depth file into different files for MaxBin to use       \n",
    "for i in $(seq 4 $N); do \n",
    "\t\tsample=$(head -n 1 ../data/working/mb2_master_depth_\"$f\".txt | cut -f $i) #dont think this line works yet\n",
    "\t\tgrep -v totalAvgDepth ${out}/work_files/mb2_master_depth.txt | cut -f 1,$i > ${out}/work_files/mb2_${sample%.*}.txt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb43a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maxbin2 final script for processing #documentation for maxbin is unavailable, do we want to continue?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d33a97",
   "metadata": {},
   "source": [
    " #### CONCOCT\n",
    " This set of commands runs CONCOCT in its standard mode. It first creates a depth/coverage file for itself to use and then runs CONCOCT, with the standard settings. This means k-mer value is set to 4, minimum contig length is 1000, and CONCOCT runs on the exact amount of slots given to it by Hydra. \n",
    " \n",
    "CONCOCT creates a depth file out of the coverance created in the mapping step. It is key that this is all in the correct places before proceeding with binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926bf611",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-7db03b054bf7>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#this creates the CONCOCT depth file\n",
    "\n",
    "#this part cuts up the contigs into 10kb pieces for CONCOCT to use !Are the chunks too large?! check filenames\n",
    "for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past\n",
    "do\n",
    "cut_up_fasta.py \"$f\".contigs-fixed.fa -c 1000 -o 0 --merge_last -b ../data/working/\"$f\"_contigs_cut.bed > ../data/working/\"$f\"_contigs_cut.fa\n",
    "\n",
    "#this part estimates contig coverage\n",
    "concoct_coverage_table.py ../data/working/\"$f\"_contigs_cut.bed ../../03_mapping/data/results/\"$f\".bam > ../data/working/coverage_table_\"$f\".tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49664758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-1ee438ed8a32>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [9]\u001b[0;36m\u001b[0m\n\u001b[0;31m    mkdir ../data/results/concoct_bins\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#CONCOCT script\n",
    "#make correct directories (can be omitted I think)\n",
    "mkdir ../data/results/concoct_bins\n",
    "mkdir ..data/working/concoct_temp\n",
    "#run the following for all your samples\n",
    "for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past\n",
    "do\n",
    "#this creates separate directories for all your samples, especially useful at later stages with many samples\n",
    "mkdir ../data/results/concoct_bins/\"$f\"_concoct_bins\n",
    "mkdir ../data/working/concoct_temp/\"$f\"_concoct_temp\n",
    "#this next bit actually runs CONCOCT itself\n",
    "concoct --composition_file ../data/working/\"$f\"_contigs_cut.fa --coverage_file ../data/working/coverage_table_\"$f\".tsv -t $NSLOTS -b ../data/working/concoct_temp/\"$f\"_concoct_temp/\n",
    "merge_cutup_clustering.py ../data/working/concoct_temp/\"$f\"_concoct_temp/clustering_gt1000.csv > ..data/working/concoct_temp/\"$f\"_concoct_temp/\"$f\"_clustering_merged.csv\n",
    "mkdir ../data/results/concoct_bins/\"$f\"_concoct_bins\n",
    "extract_fasta_bins.py \"$f\"_assembly.fa ..data/working/concoct_temp/\"$f\"_concoct_temp/\"$f\"_clustering_merged.csv --output_path ../data/results/concoct_bins/\"$f\"_concoct_bins\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10818cf",
   "metadata": {},
   "source": [
    "### Continuing\n",
    "You should now have 3 sets of bins, each created with a slightly different algorithm. It is now important to run the CheckM software with the script below and generate output files for all of them. This will inform you towards the quality of your bins and your contamination/completion rate. After this, you can proceed to the \"Refine Bins\" part of the workflow.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

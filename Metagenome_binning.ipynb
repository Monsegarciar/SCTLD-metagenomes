{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b24a3a",
   "metadata": {},
   "source": [
    "### Preparing assembly files for binning\n",
    "To create a depth processing file, reads must be re-aligned to the contigs. This has been done using bowtie2 (can also be done using BWA). The next step would be to create a depth file with MetaBat2, convert that to be suitable for CONCOCT and MaxBin2, and then process these into bins. \n",
    "\n",
    "This is all assuming you have installed all of the softwares mentioned here. Use conda for quick install. If needed, the documentation for everything can be found here:\n",
    "\n",
    "MetaBat2: \n",
    "\n",
    "MaxBin2:\n",
    "\n",
    "CONCOCT: https://github.com/BinPro/CONCOCT\n",
    "\n",
    "CheckM: https://github.com/Ecogenomics/CheckM/wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da1fd1",
   "metadata": {},
   "source": [
    "#### MetaBat2\n",
    "The first piece of code here generates a fairly simple text file for the coverage of these files. The next set of code runs MetaBat2  (v2.10.2) using minContig 2500, minCV 1.0, minCVSum 1.0, maxP 95%, minS 60, and maxEdges 200. It gathers all mapping information into a single depth file, so you can use your 1 file in the next analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a03a1a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5d2ab8b6c55f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for f in Coral1 Coral2 Coral4 Coral5\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#this creates a depth file for MetaBat\n",
    "jgi_summarize_bam_contig_depths --outputDepth ../data/working/metabat_depth_co-assembly1.txt ../../03_mapping/data/results/*.bam\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d5f1db",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-87bf656f4fdd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [11]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for f in Coral1 Coral2 Coral4 Coral5 T3-21-Mmea T3-4-Past\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#this is the actual MetaBat2 script\n",
    "metabat2 -i ../../02_assembly/data/contigs-anvio/\"$f\".contigs-fixed.fa -a depth.txt \\\n",
    "-o ../data/working/metabat_depth_\"$f\".txt \\\n",
    "-v \\\n",
    "-m 1500 \\\n",
    "-s 200 \\#this is much lower than they do, kinda worried about this one... should I bin all the samples at once or bin them all seprarately? \\\n",
    "-l --unbinned \\\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d33a97",
   "metadata": {},
   "source": [
    " #### CONCOCT\n",
    " This set of commands runs CONCOCT in its standard mode. It first creates a depth/coverage file for itself to use and then runs CONCOCT, with the standard settings. This means k-mer value is set to 4, minimum contig length is 1000, and CONCOCT runs on the exact amount of slots given to it by Hydra. \n",
    " \n",
    "CONCOCT creates a depth file out of the coverance created in the mapping step. It is key that this is all in the correct places before proceeding with binning. It creates a single file, which is then used for the complete binning process. Do keep in mind that binning might take awhile, so be prepared to let this run overnight.\n",
    "\n",
    "IMPORTANT: in the current version of CONCOCT, you're missing a vital file, called libmkl.so. Without this file, CONCOCT will not be able to start. You can fix this issue by installing another file through Conda: \n",
    "\n",
    "conda install mkl\n",
    "\n",
    "Additionally, samtools will not work properly after a fresh CONCOCT install. The easiest way to fix this is to go to your environment where you installed CONCOCT and force an update through conda. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926bf611",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-f36314307c24>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    cut_up_fasta.py ../../02_assembly/data/results/contigs_fixed/co-assembly1.contigs-fixed.fa -c 1000 -o 0 --merge_last -b ../data/working/co-assembly1_contigs_cut.bed > ../data/working/co-assembly1_contigs_cut.fa\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#this creates the CONCOCT depth file\n",
    "\n",
    "#this part cuts up the contigs into 10kb pieces for CONCOCT to use \n",
    "cut_up_fasta.py ../../02_assembly/data/results/contigs_fixed/co-assembly1.contigs-fixed.fa -c 1000 -o 0 --merge_last -b ../data/working/co-assembly1_contigs_cut.bed > ../data/working/co-assembly1_contigs_cut.fa\n",
    "#this part estimates contig coverage\n",
    "concoct_coverage_table.py ../data/working/co-assembly1_cut.bed ../../03_mapping/data/results/*.bam > ../data/working/coverage_table_co-assembly1.tsv\n",
    "\n",
    "#this script needs an error output! second part will fail and give no notice, causing CONCOCT to fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49664758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-1ee438ed8a32>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [9]\u001b[0;36m\u001b[0m\n\u001b[0;31m    mkdir ../data/results/concoct_bins\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#CONCOCT script\n",
    "#make correct directories (can be omitted I think)\n",
    "mkdir ../data/results/concoct_bins\n",
    "mkdir ..data/working/concoct_temp\n",
    "\n",
    "#this next bit actually runs CONCOCT itself\n",
    "concoct --composition_file ../data/working/co_assembly1_cut.fa --coverage_file ../data/working/coverage_table_\"$f\".tsv -t $NSLOTS -b ../data/working/concoct_temp/\"$f\"_concoct_temp/\n",
    "merge_cutup_clustering.py ../data/working/concoct_temp/\"$f\"_concoct_temp/clustering_gt1000.csv > ..data/working/concoct_temp/\"$f\"_concoct_temp/\"$f\"_clustering_merged.csv\n",
    "mkdir ../data/results/concoct_bins/\"$f\"_concoct_bins\n",
    "extract_fasta_bins.py \"$f\".contigs.fa ..data/working/concoct_temp/\"$f\"_concoct_temp/\"$f\"_clustering_merged.csv --output_path ../data/results/concoct_bins/\"$f\"_concoct_bins\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a53cc6",
   "metadata": {},
   "source": [
    "### Binsanity\n",
    "This is another binning software that can be used. *Under construction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d89875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be26172",
   "metadata": {},
   "source": [
    "### DAS_tool\n",
    "This is a tool to recombine all your bins from several different algorithms into a single one, without redundancy *under construction*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10818cf",
   "metadata": {},
   "source": [
    "### Continuing\n",
    "You should now have 3 sets of bins, each created with a slightly different algorithm. It is now important to run the CheckM software with the script below and generate output files for all of them. This will inform you towards the quality of your bins and your contamination/completion rate. After this, you can proceed to the \"Refine Bins\" part of the workflow.\n",
    "\n",
    "CheckM runs a check against a database to determine the levels of completeness versus contamination. These statistics are vital in determining how you want to proceed in the refinement process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3656d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23d2943",
   "metadata": {},
   "source": [
    "## Quality control\n",
    "To see whether a dataset is worth processing, it is necessary to assess the quality of the dataset.This set of code is run on the raw reads from the Illumina sequencer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecb3e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-896ea53919a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    fastqc ../data/working/*.fastq \\\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fastqc ../data/working/*.fastq \\\n",
    "--outdir=../data/results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65840b1",
   "metadata": {},
   "source": [
    "This script does what it needs to, but kind of indiscriminately dumps everything in control. Kind of want to add a step where it puts everything together in a nice little box. The next step is to trim reads using Trimgalore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3ebd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to write this script Trimgalore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea76869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an additional filtering step you can take\n",
    "iu-gen-configs ../data/working/cavernosa_samples.txt -o ../data/working/quality_configs\n",
    "iu-filter-quality-minoche ../data/working/quality_configs/Coral1.ini\n",
    "iu-filter-quality-minoche ../data/working/quality_configs/Coral2.ini\n",
    "iu-filter-quality-minoche ../data/working/quality_configs/Coral3.ini\n",
    "iu-filter-quality-minoche ../data/working/quality_configs/Coral4.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae09ec74",
   "metadata": {},
   "source": [
    "Your samples file needs to be a tab-delimited file with in the first column your sample name, in the second column the corresponding R1 file path, and in the third column your corresponding R2 file path. THE FIRST ROW MUST BE 'Sample' 'r1' and 'r2' OR IT WON'T DO ANYTHING. \n",
    "\n",
    "Aside from that, this software won't run if the filename is occupied, for fear of removing important information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a351a",
   "metadata": {},
   "source": [
    "### Read normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "SAMPLENAME=\n",
    "READSPATH=\n",
    "SCRIPTPATH=\n",
    "OUTPATH=\n",
    "READNAME1= read_name_without_variable_part_R1\n",
    "READNAME2= read_name_without_variable_part_R2\n",
    "\n",
    "#check paths\n",
    "\n",
    "\n",
    "#normalise reads in a loop\n",
    "for f in Coral1 Coral2 Coral4 Coral5\n",
    "do\n",
    "$SCRIPTPATH/bbnorm.sh in=$READSPATH/\"f\"_\"$READNAME1\".fq out=\"OUTPATH\"/\"$f\"_norm_R1.fq target=70 min=5 || { echo 'Forward reads not normalised, exiting.' && exit; }\n",
    "$SCRIPTPATH/bbnorm.sh in=$READSPATH/\"f\"_\"$READNAME2\".fq out=\"OUTPATH\"/\"$f\"_norm_R2.fq target=70 min=5 || { echo 'Reverse reads not normalised, exiting.' && exit; }\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c16e7c",
   "metadata": {},
   "source": [
    "### Read filtering\n",
    "To remove host reads, I have used Bowtie2's \"build\" function to create an index of the genome that was available, then aligned those using bowtie2. Then you separate mapped and unmapped reads using samtools, which can also separate them into different files and re-purpose them into fastq files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters:\n",
    "SAMPLENAME=\n",
    "GENOME=\n",
    "READSPATH=/path/to/reads/\n",
    "INDEX=\"$GENOME\"_DB\n",
    "\n",
    "#this is how you build a bowtie2 index from a known genome:\n",
    "bowtie2-build ../data/working/M.cavernosa.fasta \"$INDEX\"\n",
    "\n",
    "#split out: bowtie2-build path/to/input index-name\n",
    "for f in <sample1> <sample2> <sample3> <sample4>\n",
    "do\n",
    "bowtie2 -p 8 -x ../data/working/$INDEX -1 \"$READSPATH\"/\"$f\"_R1_001_val_1.fq -2 \"$READSPATH\"/\"$f\"_R2_001_val_2.fq -S ../data/working/\"$f\"_mapped_and_unmapped.sam\n",
    "#this re-aligns your reads back to the index;\n",
    "\n",
    "samtools view -bS ../data/working/\"$f\"_mapped_and_unmapped.sam > ../data/working/\"$f\"_mapped_and_unmapped.bam\n",
    "#this converts the sam file from bowtie to a bam file for processing\n",
    "\n",
    "samtools view -b -f 12 -F 256 ../data/working/\"$f\"_mapped_and_unmapped.bam > ../data/working/\"$f\"_bothReadsUnmapped.bam\n",
    "#this extracts only the reads of which both do not match against the host genome\n",
    "\n",
    "samtools sort -n -m 5G -@ 2 ../data/working/\"$f\"_bothReadsUnmapped.bam -o ../data/working/\"$f\"_bothReadsUnmapped_sorted.bam\n",
    "samtools fastq -@ 8 ../data/working/\"$f\"_bothReadsUnmapped_sorted.bam \\\n",
    "    -1 \"$f\"_host_removed_R1.fastq \\\n",
    "    -2 \"$f\"_host_removed_R2.fastq \\\n",
    "    -0 /dev/null -s /dev/null -n\n",
    "\n",
    "#this sorts the file so both mates are together and then extracts them back as .fastq files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c3d04",
   "metadata": {},
   "source": [
    "This leaves you with trimmed, filtered reads. After this, you should run FastQC again. Be mindful that you change its logging location and the name of the directory, OR IT WILL OVERWRITE THE OTHER FILES. Now comes the first step towards a metagenomic workflow: combining your read files. Mark this well: in order for this to be scientifically accurate, you need to combine samples that are somehow connected: \n",
    "* A time series of samples works\n",
    "* A series of samples of the same habitat/species\n",
    "* The same sample, taken in different locations\n",
    "\n",
    "To practice, its perfectly okay to combine your samples at random. To find something interesting, do as above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bac38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code will combine your read files into large files that can be used for de novo co-assembly\n",
    "cat *_R1.fastq > reads_R1_ALL.fastq\n",
    "cat *_R2.fastq > reads_R2_ALL.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444cfe2",
   "metadata": {},
   "source": [
    "Now, you are ready to proceed with the de novo co-assembly of your samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

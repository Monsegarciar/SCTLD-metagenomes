{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23d2943",
   "metadata": {},
   "source": [
    "## Quality control\n",
    "To see whether a dataset is worth processing, it is necessary to assess the quality of the dataset.This set of code is run on the raw reads from the Illumina sequencer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eecb3e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-896ea53919a6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    fastqc ../data/working/*.fastq \\\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fastqc ../data/working/*.fastq \\\n",
    "--outdir=../data/results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65840b1",
   "metadata": {},
   "source": [
    "This script does what it needs to, but kind of indiscriminately dumps everything in control. Kind of want to add a step where it puts everything together in a nice little box. The next step is to trim reads using Trimgalore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3ebd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to write this script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c16e7c",
   "metadata": {},
   "source": [
    "### Read filtering\n",
    "To remove host reads, I have used Bowtie2's \"build\" function to create an index of the genome that was available, then aligned those using bowtie2. Then you separate mapped and unmapped reads using samtools, which can also separate them into different files and re-purpose them into fastq files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2357468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how you build a bowtie2 index from a known genome:\n",
    "bowtie2-build ../data//bowtie-index/M.cavernosa.fasta M.cavernosa_DB\n",
    "\n",
    "#split out: bowtie2-build path/to/input index-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cd1d73",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-f91a8a36e7e4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [2]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for f in <sample1> <sample2> <sample3> <sample4>\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for f in <sample1> <sample2> <sample3> <sample4>\n",
    "do\n",
    "bowtie2 -p 8 -x ../reference/bowtie-index/M.cavernosa -1 ../../00_raw/\"$f\"_R1_001_val_1.fq -2 ../../00_raw/\"$f\"_R2_001_val_2.fq -S ../data/working/\"$f\"_mapped_and_unmapped.sam\n",
    "#this re-aligns your reads back to the index;\n",
    "\n",
    "samtools view -bS ../data/working/\"$f\"_mapped_and_unmapped.sam > ../data/working/\"$f\"_mapped_and_unmapped.bam\n",
    "#this converts the sam file from bowtie to a bam file for processing\n",
    "\n",
    "samtools view -b -f 12 -F 256 ../data/working/\"$f\"_mapped_and_unmapped.bam > ../data/working/\"$f\"_bothReadsUnmapped.bam\n",
    "#this extracts only the reads of which both do not match against the host genome\n",
    "\n",
    "samtools sort -n -m 5G -@ 2 ../data/working/\"$f\"_bothReadsUnmapped.bam -o ../data/working/\"$f\"_bothReadsUnmapped_sorted.bam\n",
    "samtools fastq -@ 8 ../data/working/\"$f\"_bothReadsUnmapped_sorted.bam \\\n",
    "    -1 \"$f\"_host_removed_R1.fastq \\\n",
    "    -2 \"$f\"_host_removed_R2.fastq \\\n",
    "    -0 /dev/null -s /dev/null -n\n",
    "\n",
    "#this sorts the file so both mates are together and then extracts them back as .fastq files\n",
    "# this is the most memory intensive step, is recommended to run as a .job prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c3d04",
   "metadata": {},
   "source": [
    "This leaves you with trimmed, filtered reads. After this, you should run FastQC again. Be mindful that you change its logging location and the name of the directory, OR IT WILL OVERWRITE THE OTHER FILES. Now comes the first step towards a metagenomic workflow: combining your read files. Mark this well: in order for this to be scientifically accurate, you need to combine samples that are somehow connected: \n",
    "* A time series of samples works\n",
    "* A series of samples of the same habitat/species\n",
    "* The same sample, taken in different locations\n",
    "\n",
    "To practice, its perfectly okay to combine your samples at random. To find something interesting, do as above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e071b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#The following code will combine your read files into large files that can be used for de novo co-assembly\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcat\u001b[49m \u001b[38;5;241m*\u001b[39m_R1\u001b[38;5;241m.\u001b[39mfastq \u001b[38;5;241m>\u001b[39m reads_R1_ALL\u001b[38;5;241m.\u001b[39mfastq\n\u001b[1;32m      3\u001b[0m cat \u001b[38;5;241m*\u001b[39m_R2\u001b[38;5;241m.\u001b[39mfastq \u001b[38;5;241m>\u001b[39m reads_R2_ALL\u001b[38;5;241m.\u001b[39mfastq\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat' is not defined"
     ]
    }
   ],
   "source": [
    "#The following code will combine your read files into large files that can be used for de novo co-assembly\n",
    "cat *_R1.fastq > reads_R1_ALL.fastq\n",
    "cat *_R2.fastq > reads_R2_ALL.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444cfe2",
   "metadata": {},
   "source": [
    "Now, you are ready to proceed with the de novo co-assembly of your samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
